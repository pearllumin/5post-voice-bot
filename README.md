# Голосовой помощник для автоматизированной обработки звонков 
![specpic](https://github.com/pearllumin/5post-voice-bot/assets/144477967/06b2e0ea-740d-4539-beae-7e45bda91baf)

## Описание проекта
Проект направлен на разработку аналитического решения для определения тематики вопросов клиентов и классификации их по тональности (позитивной, нейтральной, негативной). Это решение предполагается использовать для автоматизированной обработки звонков в голосовом помощнике.

## Цели проекта
- **Эффективность**: Увеличение автоматизации позволит компании снизить трудоемкость колл-центра и перераспределить ресурсы на более важные задачи.
- **Качество обслуживания**: Благодаря быстрому решению стандартных запросов клиентов, повышается клиентский NPS.
- **Инновации**: Применение ML для оптимизации голосового бота демонстрирует технологический прогресс и конкурентные преимущества компании.
  
## Методика решения

### Этапы проекта:

1. **Предобработка вопросов**:

    - **Обработка специфичных слов**: таких как сокращения, свойственные компании-заказчику.
    - **Удаление стоп-слов**: для повышения качества анализа, список стоп-слов был взят из библиотеки **`nltk.corpus`** и расширен на этапе тематического моделирования путем исключения часто встречающихся слов, не имеющих смысловой нагрузки.
    - **Нормализация текстовых данных**: удаление знаков препинания и символов.
    - **Удаление выбросов**.

2. **Тематическое моделирование**:

    - Использование подходов [LDA (Latent Dirichlet Allocation)](https://www.jmlr.org/papers/volume3/blei03a/blei03a.pdf), [CTM (Correlated Topic Model)](https://github.com/MilaNLProc/contextualized-topic-models), GSDMM (Gibbs Sampling Dirichlet Mixture Model) для выделения тем, которые обсуждают клиенты в своих вопросах.
      - **Примеры тем**:
        - Получение кода товара
        - Запрос о сроке хранения заказа
  

3. **Тегирование отзывов**:

    - Использование классификатора [fasttext ](https://fasttext.cc/docs/en/supervised-tutorial.html) для классификации вопросов клиентов.

## Итоги base line

### 1. Тематическое моделирование (использовали подход LDA)

Анализ выделенных тем показал, что с помощью LDA удалось выделить только крупные классы, в то время как более мелкие классы выделялись нечетко. На данном этапе было выделено 4 класса.

### 2. Тегирование отзывов

Выбрали fasttext на данном этапе из-за его легковесности и быстроты обучения модели. Для 4 классов получили точность (accuracy) 97%.

### 3. Общие итоги 

Классификатор работает хорошо на четырех классах, однако данные нуждаются в более детальной разметке на большее количество классов.

## Дальнейшие шаги

### 1. Дополнительная разметка данных

Были попробованы два дополнительных метода разметки данных:

- **K-means**: Этот метод показал более адекватные результаты по сравнению с LDA.
- **Логика + K-means**:
  - Нормализовали текстовые данные.
  - С помощью **`value_counts()`** выделили самые большие классы по вхождению слов и словосочетаний. Выделили 11 основных классов, которые составили около 65% от всего датасета. Остальные 9 классов выделили с помощью K-means.

В итоге получили два размеченных датасета:

- По методу K-means.
- Логическим методом + K-means.

### 2. Обучение классификаторов

Для каждого из размеченных датасетов обучили три классификатора:

- **Fasttext**
- **Случайный лес**
- **Roberta** (на эмбеддингах Deep Pavlov)

### 3. Результаты

Результаты классификации представлены в таблице:

| Тип размеченных данных | Модель классификации | Кол-во классов | Accuracy |
|-------------------------|----------------------|----------------|----------|
| K-means                 | fasttext             | 19             | 0.93     |
| K-means                 | random_forest        | 19             | 0.95     |
| K-means                 | ruberta              | 19             | 0.92     |
| логика + K-means        | fasttext             | 20             | 0.96     |
| логика + K-means        | random_forest        | 20             | 0.96     |
| логика + K-means        | ruberta              | 20             | 0.95     |

## Заключение

В рамках данного проекта были исследованы различные методы для тематического моделирования и классификации вопросов клиентов.
- **Лучший подход**: Комбинация логических методов с кластеризацией K-means дает наиболее точные результаты для классификации вопросов клиентов.
- **Производительность моделей**: Хорошие результаты показали **`random forest`** и **`fasttext`**. Fastext очень легковесный и считается в десятки, а то и в сотни раз быстрее всех остальных, а качество по метрикам не хуже. Также стоит отметить **`rubert transformer`**. Нам хватило ресурсов на одну эпоху, но даже на ней accuracy 95%. Возможно у rubert самый большой потенциал по качеству классификации. Но его минус в том, что он требует очень много ресурсов.
